{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the StarNet Model\n",
    "\n",
    "This notebook takes you through the steps of how to train a StarNet Model\n",
    "- Required Python packages: `numpy h5py keras`\n",
    "- Required data files: training_data.h5, mean_and_std.npy\n",
    "\n",
    "Note: We use tensorflow for the keras backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of norm rvsflux: (300, 1134)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, InputLayer, Flatten, Reshape, Concatenate, concatenate\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import HDF5Matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "\n",
    "\n",
    "#Loading the data\n",
    "\n",
    "\n",
    "#RVSFlux\n",
    "pathrvs = '/Users/aishasultan/work/synple-gaia/run/CNN/age_parameter/RVS/spectra/normspectra_feh_pos00+pos.25+neg.25.npy'\n",
    "norm_rvsflux = np.load (pathrvs)\n",
    "print('shape of norm rvsflux:', np.shape(norm_rvsflux))\n",
    "\n",
    "for i in range(np.shape(norm_rvsflux)[0]):\n",
    "    plt.plot(np.arange(1134), norm_rvsflux[i,:])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of bpflux: (300, 33)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#BPFlux\n",
    "pathbp = '/Users/aishasultan/work/synple-gaia/run/CNN/age_parameter/BP/spectra/spectra_feh_pos00+pos.25+neg.25.h5'\n",
    "readbp = h5py.File(pathbp, 'r') \n",
    "bpflux = readbp.get('bpflux')\n",
    "bpflux = np.array(bpflux)\n",
    "print('shape of bpflux:', np.shape(bpflux))\n",
    "\n",
    "\n",
    "norm_bpflux= []\n",
    "\n",
    "for ii in range(np.shape(bpflux)[0]):    \n",
    "    max_flux= np.max(bpflux[ii])\n",
    "    normflux = bpflux[ii]/ max_flux\n",
    "    #plt.plot(np.arange(33), normflux)\n",
    "    #print('normflux:',normflux)\n",
    "    norm_bpflux.append(normflux)\n",
    "        \n",
    "\n",
    "        \n",
    "norm_bpflux= np.array(norm_bpflux)\n",
    "\n",
    "#print('shape of norm bpflux:', np.shape(norm_bpflux))\n",
    "#print('shape of norm bpflux:', print(norm_bpflux[0:10]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['rpflux']>\n",
      "shape of rpflux: (300, 40)\n"
     ]
    }
   ],
   "source": [
    "#RPFlux\n",
    "pathrp = '/Users/aishasultan/work/synple-gaia/run/CNN/age_parameter/RP/spectra/spectra_feh_pos00+pos.25+neg.25.h5'\n",
    "readrp = h5py.File(pathrp, 'r')\n",
    "print(readrp.keys())\n",
    "rpflux = readrp.get('rpflux')\n",
    "rpflux = np.array(rpflux)\n",
    "print('shape of rpflux:', np.shape(rpflux))\n",
    "\n",
    "\n",
    "norm_rpflux= []\n",
    "for ii in range(np.shape(rpflux)[0]):\n",
    "        max_flux= np.max(rpflux[ii])\n",
    "        normflux = rpflux[ii]/ max_flux\n",
    "        #plt.plot(np.arange(40), normflux)\n",
    "        #print('normflux:',normflux)\n",
    "        norm_rpflux.append(normflux)\n",
    "\n",
    "        \n",
    "norm_rpflux= np.array(norm_rpflux)\n",
    "\n",
    "#print('shape of norm_rpflux:', np.shape(norm_rpflux))\n",
    "#print('output of norm_flux:', print(norm_rpflux[0:10]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['age_sel', 'feh_sel', 'logg_sel', 'logteff_sel']>\n",
      "10.3\n",
      "Fe/H: [ 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25\n",
      "  0.25  0.25  0.25  0.25  0.25  0.25  0.25  0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25\n",
      " -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25 -0.25]\n",
      "age: [ 9.65  8.    7.75  9.75  8.35  9.75  7.5   7.9   9.35  9.1   7.75  9.65\n",
      "  7.5   8.05  9.35  8.55  9.05  5.45  7.65  8.35  9.65  8.6   8.9   9.2\n",
      "  8.4   8.65  8.05  7.5   7.55  9.1   9.25 10.2   7.4   8.95  6.4   9.8\n",
      "  8.15 10.2   9.35  7.35  7.5   8.15  9.4   9.15  9.35  8.55  9.85  9.5\n",
      "  8.75 10.25  8.65  6.45  9.4  10.2   9.55 10.3   7.5   8.35  8.7  10.3\n",
      "  9.5   7.95  7.75  7.75  8.35  9.15  7.65  8.1   7.7   7.45  7.75  7.75\n",
      "  6.8   7.75  8.1   9.7   6.5   6.15  8.7   6.8   7.7   9.3   8.5   8.5\n",
      "  9.45  9.65  8.8  10.3  10.25  9.95  8.    8.95 10.05  8.75  8.75  9.4\n",
      "  9.95  8.45  9.2   7.95  9.6   8.15  7.55  7.75  8.1   8.85 10.    9.8\n",
      "  7.65  9.6   7.9   7.95  9.    8.95  9.25  7.75  9.95  8.9   8.65  8.55\n",
      "  9.65  9.9   9.05  9.3   6.    7.8   8.25  7.3   9.15  8.85  7.85  8.3\n",
      "  8.65  8.    9.6   7.6   8.2   8.2   8.8   7.8   9.1   8.95  9.2   8.05\n",
      "  9.5   7.3   7.1   8.85  8.1   9.85  9.65  8.85  8.9   8.5   8.85  8.4\n",
      "  9.35  9.3   9.6   8.05  9.8   9.65  9.    9.9   9.3   7.55  9.45 10.25\n",
      "  8.05  8.7   7.85  8.55  9.45  7.5   7.8  10.05  8.5   9.2   8.1   7.6\n",
      "  8.25  7.9  10.15  8.4   9.    7.2  10.25  8.3   8.   10.05 10.1   8.95\n",
      "  8.1   8.45  9.75  8.2  10.05  9.35 10.3   9.8   8.8   8.1   9.8   8.5\n",
      "  9.    7.95 10.2  10.3   9.3  10.15  8.45  8.55  8.9   8.2   8.5   9.65\n",
      "  8.35  7.95  9.45  9.    6.45  7.05  9.65  9.2   7.65  7.9   8.15  7.75\n",
      "  9.7   9.5   6.8   9.45  8.95  8.85  9.4   7.4   7.95  9.65  9.95  9.45\n",
      "  8.75 10.1   7.55  5.9   7.45  6.9   7.9   8.45  9.45  9.15  7.65  8.25\n",
      " 10.    7.85  7.1   8.25  9.75  7.55  9.8   9.6   7.7   8.6   7.75  7.65\n",
      "  7.55  8.65 10.15  9.95 10.3   9.1  10.15  8.95  8.55  7.9   8.45  8.4\n",
      " 10.    8.35  9.1  10.2   8.9  10.2  10.    9.2   8.   10.15 10.3   9.2\n",
      "  9.15  9.45  9.1   8.5   7.85  7.    9.1  10.05  9.5  10.1   8.55  8.6 ]\n",
      "logteff [3.54248999 3.6066258  3.7873671  3.46597127 3.62798319 3.76763759\n",
      " 4.29615231 3.91626525 3.71619288 3.58785671 4.14298415 3.58227938\n",
      " 3.57011732 4.15370233 3.66858903 3.68178937 3.60580053 4.39416097\n",
      " 4.07097861 3.50630386 3.49803057 3.63597952 3.91385471 3.85667932\n",
      " 3.63372168 3.93419122 4.07767167 4.15105956 4.06254364 3.860316\n",
      " 3.65266624 3.66393719 4.01820587 3.54799754 4.18172789 3.66489556\n",
      " 3.76521597 3.5446333  3.65815058 4.31274884 4.18869583 3.69570367\n",
      " 3.52164375 3.60698608 3.62602704 3.68150915 3.53120101 3.61751628\n",
      " 3.94557227 3.56289245 3.94605639 4.15175342 3.60749727 3.54507231\n",
      " 3.53741808 3.53842999 4.22528664 3.73351704 3.67510712 3.51109124\n",
      " 3.53708848 3.53628698 4.03406552 4.23045994 4.06424796 3.65057189\n",
      " 3.79074541 3.61568024 4.12020865 3.93656088 4.13999126 3.62075933\n",
      " 4.05747862 3.71034674 3.84142046 3.79197531 4.15151964 4.36266659\n",
      " 3.60991799 4.11367309 4.1797129  3.75108667 3.99391259 3.65085076\n",
      " 3.52507406 3.51790975 3.69652093 3.62640799 3.60736569 3.65074899\n",
      " 3.65515452 3.8997092  3.50116319 3.64425246 3.94120836 3.64939974\n",
      " 3.59180444 3.63958185 3.67454181 3.83317173 3.56971807 3.59987587\n",
      " 3.72133389 3.75816806 3.70975663 3.89850037 3.60865645 3.64933488\n",
      " 4.25465385 3.67652282 4.15875604 4.08833038 3.86822333 3.65242768\n",
      " 3.54881541 4.00716335 3.43007701 3.72326351 3.97827174 3.50074242\n",
      " 3.49929962 3.58858143 3.62265815 3.49946155 4.30166939 4.18107503\n",
      " 3.63665222 4.21971724 3.57119235 3.68394531 4.17616169 4.05084673\n",
      " 3.67544225 4.12663558 3.63264933 4.24491213 4.09592517 3.59412539\n",
      " 3.91967469 3.69026702 3.80910219 3.62573982 3.66293534 4.09150591\n",
      " 3.59705337 4.03947756 4.20388142 3.67608639 3.50157387 3.55367458\n",
      " 3.44209978 3.85746777 3.63235805 3.62385571 3.65119063 3.7486045\n",
      " 3.61723997 3.45894527 3.68624332 3.69908907 3.50520221 3.60646883\n",
      " 3.74822392 3.4762013  3.78784933 3.55523178 3.59934297 3.51693532\n",
      " 3.49091262 3.93432618 3.64171557 3.65760285 3.69389572 3.91045291\n",
      " 3.71955533 3.5342387  3.66716787 3.73013043 3.57839175 3.603552\n",
      " 3.9721132  3.84242636 3.51103836 3.61128488 3.64210652 4.06105991\n",
      " 3.64425419 3.61764666 3.50422622 3.71573589 3.57989735 3.60844276\n",
      " 3.64829103 3.95258443 3.48019338 3.48811688 3.61173114 3.79922818\n",
      " 3.70107937 3.61180637 3.93759585 4.09677057 3.53863271 4.05121688\n",
      " 3.68711368 3.80713121 3.61425997 3.67253634 3.71444117 3.68995324\n",
      " 3.52423495 4.0297585  3.67757455 3.67302218 3.91817582 3.55988254\n",
      " 3.64502413 3.78601199 3.56122107 3.65539622 4.33292254 4.37860887\n",
      " 3.67939238 3.55392938 3.91427271 3.54169472 4.11790151 3.5566089\n",
      " 3.50917714 3.68280002 4.3358323  3.56335811 3.93386545 3.58569322\n",
      " 3.6519773  4.0396321  4.07193663 3.65675205 3.57010846 3.64772212\n",
      " 3.70555931 3.62358404 4.28463678 4.37380149 3.58823935 4.13101423\n",
      " 3.71242019 3.66627859 3.81614964 3.68842758 3.58134226 4.11714724\n",
      " 3.77258712 4.22440566 4.18628623 3.60533507 3.68241126 3.68201356\n",
      " 3.62470808 3.79413769 4.23025201 3.82189203 3.79629635 3.54852134\n",
      " 4.00810568 3.60744638 3.62367848 3.66977298 3.56383849 3.66387865\n",
      " 3.68033409 3.69545743 3.67773703 3.53280212 3.68900587 3.80998967\n",
      " 3.58649382 4.03878712 3.67143534 3.56910525 3.95223638 3.68993871\n",
      " 3.67938214 3.6182794  3.62645447 3.73378851 3.70193911 3.65992793\n",
      " 3.63277312 3.6452512  3.90602733 3.8313097  3.53496872 4.2501475\n",
      " 3.88146507 3.66719175 3.54016526 3.63988799 3.64963993 3.68345714]\n"
     ]
    }
   ],
   "source": [
    "mist0 = '/Users/aishasultan/work/MIST/feh_pos0.00_100randstr_EEP0.h5'\n",
    "mist1 = '/Users/aishasultan/work/MIST/feh_pos.25_100randstr_EEP0.h5'\n",
    "mist2 = '/Users/aishasultan/work/MIST/feh_neg.25_100randstr_EEP0.h5'\n",
    "\n",
    "\n",
    "\n",
    "readmist0 = h5py.File(mist0, 'r')\n",
    "readmist1 = h5py.File(mist1, 'r')\n",
    "readmist2 = h5py.File(mist2, 'r')\n",
    "\n",
    "\n",
    "#reading MIST0 file\n",
    "print(readmist0.keys())\n",
    "mist_logteff0 = readmist0.get('logteff_sel')\n",
    "teff_sel0 = np.array(mist_logteff0)\n",
    "mist_logg0 = readmist0.get ('logg_sel')\n",
    "logg_sel0 = np.array(mist_logg0)\n",
    "mist_feh0 = readmist0.get ('feh_sel')\n",
    "feh_sel0 = np.array(mist_feh0)\n",
    "mist_age0 = readmist0.get ('age_sel')\n",
    "age_sel0 = np.array(mist_age0)\n",
    "\n",
    "\n",
    "#reading MIST1 file\n",
    "#print(readmist1.keys())\n",
    "mist_logteff1 = readmist1.get('logteff_sel')\n",
    "teff_sel1 = np.array(mist_logteff1)\n",
    "mist_logg1 = readmist1.get ('logg_sel')\n",
    "logg_sel1 = np.array(mist_logg1)\n",
    "mist_feh1 = readmist1.get ('feh_sel')\n",
    "feh_sel1 = np.array(mist_feh1)\n",
    "mist_age1 = readmist1.get ('age_sel')\n",
    "age_sel1 = np.array(mist_age1)\n",
    "\n",
    "#reading MIST2 file\n",
    "#print(readmist1.keys())\n",
    "mist_logteff2 = readmist2.get('logteff_sel')\n",
    "teff_sel2 = np.array(mist_logteff2)\n",
    "mist_logg2 = readmist2.get ('logg_sel')\n",
    "logg_sel2 = np.array(mist_logg2)\n",
    "mist_feh2 = readmist2.get ('feh_sel')\n",
    "feh_sel2 = np.array(mist_feh2)\n",
    "mist_age2 = readmist2.get ('age_sel')\n",
    "age_sel2 = np.array(mist_age2)\n",
    "\n",
    "\n",
    "#MIST all parameters\n",
    "logteff = np.hstack((teff_sel0, teff_sel1, teff_sel2))\n",
    "logg = np.hstack ((logg_sel0, logg_sel1, logg_sel2))\n",
    "feh = np.hstack ((feh_sel0, feh_sel1, feh_sel2))\n",
    "age = np.hstack ((age_sel0, age_sel1, age_sel2)) #it is in Giga, Mega years\n",
    "\n",
    "\n",
    "\n",
    "print(age.max())\n",
    "print('Fe/H:',feh)\n",
    "print('age:',age)\n",
    "print('logteff',logteff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of input stars = 300\n",
      "number of RVS training data= 232\n",
      "number of BP training data= 232\n",
      "number of RP training data= 232\n",
      "The size of CVS for the input flux data\n",
      "RVS cvs= (68, 1134)\n",
      "BP cvs= (68, 33)\n",
      "RP cvs= (68, 40)\n",
      "the size of output label= (232,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#features\n",
    "num_tot = len(logteff)\n",
    "print('total number of input stars =', num_tot)\n",
    "plim = 0.8\n",
    "ran_frac = np.random.uniform(0,1,num_tot)\n",
    "#print('ranfrac=' , ran_frac)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Input flux data of RVS, BP, RP\n",
    "x_RVStrain = norm_rvsflux[ran_frac < plim, :]\n",
    "print('number of RVS training data=', len(x_RVStrain[:,0]))\n",
    "x_RVScv = norm_rvsflux[ran_frac >= plim, :] #test set we left for the application\n",
    "\n",
    "x_BPtrain = norm_bpflux[ran_frac < plim, :]\n",
    "print('number of BP training data=', len(x_BPtrain[:,0]))\n",
    "x_BPcv = norm_bpflux[ran_frac >= plim, :]\n",
    "\n",
    "x_RPtrain =norm_rpflux[ran_frac < plim, :]\n",
    "print('number of RP training data=', len(x_RPtrain[:,0]))\n",
    "x_RPcv = norm_rpflux[ran_frac >= plim, :]\n",
    "\n",
    "\n",
    "#print('x_BPtrain', x_BPtrain)\n",
    "\n",
    "#x_train_combined = np.vstack (x_RVStrain[0,:], x_RPtrain[0,:]) \n",
    "\n",
    "#output label which is the logteff, log g, feh, and age\n",
    "y_logteff_train = logteff[ran_frac< plim]\n",
    "y_logteff_cv = logteff[ran_frac >= plim] #test set\n",
    "\n",
    "y_logg_train = logg[ran_frac< plim]\n",
    "y_logg_cv = logg[ran_frac >= plim] #test set\n",
    "\n",
    "y_feh_train = feh[ran_frac< plim]\n",
    "y_feh_cv = feh[ran_frac >= plim] #test set\n",
    "\n",
    "y_age_train = age[ran_frac< plim]\n",
    "y_age_cv = age[ran_frac >= plim] #test set\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('The size of CVS for the input flux data')\n",
    "print('RVS cvs=', np.shape(x_RVScv))\n",
    "print('BP cvs=', np.shape(x_BPcv))\n",
    "print('RP cvs=', np.shape(x_RPcv))\n",
    "\n",
    "print('the size of output label=', np.shape(y_logteff_train) )\n",
    "\n",
    "#id = np.linspace(0, len(x_RVStrain[:, 0])-1, len(x_RVStrain[:, 0]))\n",
    "#plt.plot(id, y_logteff_train)\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Normalization **\n",
    "\n",
    "Write a function to normalize the output labels. Each label will be normalized to have approximately have a mean of zero and unit variance.\n",
    "\n",
    "NOTE: This is necessary to put output labels on a similar scale in order for the model to train properly, this process is reversed in the test stage to give the output labels their proper units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#def normalize(labels):\n",
    "    # Normalize labels\n",
    "    #mean_labels=np.mean(labels)\n",
    "    #std_labels=np.std(labels)\n",
    "    #return (labels-mean_labels) / std_labels \n",
    "\n",
    "def normalize(labels):\n",
    "    max_labels = (labels).max()\n",
    "    min_labels = (labels).min()\n",
    "    norm_labels = ((labels) - min_labels) / (max_labels - min_labels)\n",
    "    return (norm_labels, max_labels, min_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type of data  <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'> <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "#normalize the y labels, the log teff and log g \n",
    "\n",
    "#output label which is the logteff and log g\n",
    "y_logteff_train = normalize(y_logteff_train)\n",
    "y_logteff_cv = normalize(y_logteff_cv)\n",
    "\n",
    "y_logg_train = normalize(y_logg_train)\n",
    "y_logg_cv = normalize(y_logg_cv)\n",
    "\n",
    "y_feh_train = normalize(y_feh_train)\n",
    "y_feh_cv = normalize(y_feh_cv) #test set\n",
    "\n",
    "y_age_train = normalize(y_age_train)\n",
    "y_age_cv = normalize(y_age_cv) #test set\n",
    "\n",
    "\n",
    "print('type of data ', type(y_logteff_train),type(y_logteff_cv),\n",
    "      type(y_logg_train),type(y_logg_cv), \n",
    "     type(y_feh_train),type(y_feh_cv), \n",
    "     type(y_age_train), type(y_age_cv))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_logteff_train: [0.10544513 0.17281034 0.36265245 0.02507348 0.19524313 0.34192951\n",
      " 0.89705634 0.49804096 0.28789442 0.73617575 0.13446357 0.74743363\n",
      " 0.23789358 0.2517586  0.17194352 1.         0.66054455 0.05874706\n",
      " 0.2036421  0.49550904 0.43545472 0.20127057 0.51686955 0.74465779\n",
      " 0.22116904 0.23300751 0.60511456 0.77687034 0.23401414 0.33938595\n",
      " 0.10769636 0.22692953 0.91448855 0.78418915 0.17318876 0.19318849\n",
      " 0.25146427 0.09358771 0.12687491 0.52933217 0.74538658 0.17372569\n",
      " 0.10815747 0.10011783 0.30609089 0.24473987 0.07246537 0.09977163\n",
      " 0.09892978 0.82805619 0.21896923 0.36620086 0.1823207  0.71225345\n",
      " 0.51935852 0.73303216 0.18765553 0.64636479 0.28175391 0.41942754\n",
      " 0.36749269 0.74514103 0.9669198  0.1762683  0.3245452  0.57959805\n",
      " 0.21926215 0.08715225 0.0796272  0.26723193 0.19358862 0.48065127\n",
      " 0.06203741 0.21233161 0.21773807 0.15724269 0.20742582 0.13404421\n",
      " 0.16572054 0.29329429 0.28113408 0.47938157 0.17494324 0.21766994\n",
      " 0.85346832 0.7527418  0.67877002 0.22091847 0.11208905 0.29532107\n",
      " 0.56316964 0.06159546 0.06008    0.15385739 0.18964996 0.90285122\n",
      " 0.77618461 0.81677257 0.13559272 0.77102388 0.63939897 0.24509189\n",
      " 0.71900399 0.20014423 0.84323608 0.68674724 0.15968051 0.50162208\n",
      " 0.26066312 0.23195521 0.62745733 0.80013936 0.24576845 0.06246877\n",
      " 0.11719289 0.         0.43628287 0.19983828 0.21961913 0.18395897\n",
      " 0.01769371 0.25643681 0.06627981 0.17264547 0.3215383  0.03581863\n",
      " 0.11882849 0.1651608  0.07860371 0.5170113  0.20966698 0.22635422\n",
      " 0.49193595 0.29142618 0.23640087 0.14315464 0.16958177 0.556701\n",
      " 0.07240982 0.17770402 0.21007761 0.65012641 0.21233342 0.06525468\n",
      " 0.14473605 0.17471879 0.21657353 0.53618891 0.04001172 0.17817275\n",
      " 0.37511077 0.2720199  0.17825177 0.52044561 0.6876352  0.10139362\n",
      " 0.63978777 0.257351   0.38341173 0.18082891 0.24203965 0.2860545\n",
      " 0.26033354 0.0862709  0.24733154 0.24254996 0.50004773 0.21314213\n",
      " 0.3612291  0.12511936 0.22403648 0.98366481 0.49594809 0.70983014\n",
      " 0.12027496 0.07045488 0.25282014 0.12736401 0.51652737 0.15082375\n",
      " 0.22044541 0.62761965 0.66155081 0.22546058 0.13445425 0.27672542\n",
      " 0.19062248 0.88496098 0.97861537 0.15349808 0.72360312 0.28393176\n",
      " 0.2354668  0.39288426 0.25873106 0.70903789 0.34712826 0.82169706\n",
      " 0.78165821 0.17145461 0.25199407 0.19180311 0.36976396 0.3989158\n",
      " 0.11178016 0.5945058  0.17367224 0.23913715 0.12786857 0.23294602\n",
      " 0.26611488 0.24750221 0.09526945 0.62673213 0.24088321 0.53582333\n",
      " 0.26031828 0.24923016 0.18505073 0.19363744 0.30637603 0.27292293\n",
      " 0.22879637 0.20027424 0.21338064 0.40880767 0.09754513 0.4614885\n",
      " 0.23642595 0.10300333 0.20774737 0.25351034]\n",
      "y_logg_train: [0.94948417 0.2381668  0.32764812 1.         0.31766636 0.84368212\n",
      " 0.7595626  0.83501819 0.87988395 0.81880199 0.11055545 0.70780622\n",
      " 0.51792334 0.48900957 0.90513455 0.83050166 0.55074406 0.02658451\n",
      " 0.34506744 0.7742137  0.73334212 0.32664614 0.66485959 0.57613892\n",
      " 0.42518602 0.56120534 0.46221004 0.83964568 0.47029858 0.46121823\n",
      " 0.1409274  0.44231618 0.68955501 0.82086976 0.29167023 0.34921613\n",
      " 0.45431124 0.95220418 0.21034739 0.8108196  0.84065934 0.29830066\n",
      " 0.14731753 0.95133798 0.49029511 0.48197177 0.07291053 0.95191823\n",
      " 0.04609983 0.70014381 0.41742758 0.85473668 0.25897085 0.8257759\n",
      " 0.83794593 0.81951887 0.24461911 0.84218333 0.34316071 0.49504455\n",
      " 0.7835552  0.84064851 0.82768072 0.27775559 0.68926315 0.80655087\n",
      " 0.39502335 0.95906385 0.0778516  0.8862848  0.34276554 0.76422279\n",
      " 0.03551227 0.39125055 0.4175035  0.9087698  0.35608909 0.240518\n",
      " 0.26720267 0.25059073 0.88072253 0.76385038 0.34671671 0.46787066\n",
      " 0.69473778 0.72413691 0.79996537 0.45132595 0.17948543 0.62103206\n",
      " 0.70368656 0.03022116 0.06278849 0.29323466 0.36982402 0.81992821\n",
      " 0.76812197 0.80535996 0.23351858 0.74224338 0.74232276 0.51147165\n",
      " 0.76932674 0.41224502 0.68357499 0.69766104 0.24855733 0.69991626\n",
      " 0.88622536 0.50356307 0.82594878 0.8145276  0.50843625 0.0072843\n",
      " 0.92631197 0.98435656 0.80214403 0.40562164 0.44159008 0.36550674\n",
      " 0.97586559 0.68304846 0.07930098 0.8962518  0.86500217 0.96085681\n",
      " 0.11573431 0.32161536 0.11112703 0.73157453 0.29828587 0.45381967\n",
      " 0.42059999 0.36871781 0.47374609 0.20250641 0.23810299 0.6099914\n",
      " 0.09554214 0.304646   0.44177949 0.8256086  0.87798653 0.00804519\n",
      " 0.29793594 0.32502977 0.36711367 0.80401192 0.95742676 0.39472832\n",
      " 0.72455847 0.78127887 0.35566344 0.7228758  0.82948056 0.0882634\n",
      " 0.72443861 0.48754858 0.85781379 0.31720941 0.88255487 0.66584316\n",
      " 0.88229894 0.01304447 0.89608897 0.39688762 0.83890859 0.33031137\n",
      " 0.36791654 0.14743435 0.40708962 0.81371264 0.43985235 0.70548785\n",
      " 0.04863185 0.01755388 0.48573261 0.94583678 0.73678527 0.18343859\n",
      " 0.38594229 0.85398525 0.60945631 0.40181809 0.18296612 0.54362059\n",
      " 0.90063093 0.69780973 0.84144247 0.10464281 0.85416481 0.30908355\n",
      " 0.40337594 0.77392337 0.49134048 0.76960954 0.79320478 0.76433622\n",
      " 0.84701907 0.20561723 0.27219998 0.33801419 0.84155452 0.57771715\n",
      " 0.02009726 0.48086155 0.23192998 0.51198085 0.14076028 0.41944331\n",
      " 0.50545267 0.42151946 0.         0.67158576 0.44919658 0.73685304\n",
      " 0.88076409 0.46941172 0.29880631 0.25525888 0.76256643 0.87221485\n",
      " 0.4079654  0.34087316 0.36717367 0.56353757 0.00136288 0.73727172\n",
      " 0.42458628 0.09401125 0.34915934 0.46952165]\n",
      "y_feh_train: [0.94948417 0.2381668  0.32764812 1.         0.31766636 0.84368212\n",
      " 0.7595626  0.83501819 0.87988395 0.81880199 0.11055545 0.70780622\n",
      " 0.51792334 0.48900957 0.90513455 0.83050166 0.55074406 0.02658451\n",
      " 0.34506744 0.7742137  0.73334212 0.32664614 0.66485959 0.57613892\n",
      " 0.42518602 0.56120534 0.46221004 0.83964568 0.47029858 0.46121823\n",
      " 0.1409274  0.44231618 0.68955501 0.82086976 0.29167023 0.34921613\n",
      " 0.45431124 0.95220418 0.21034739 0.8108196  0.84065934 0.29830066\n",
      " 0.14731753 0.95133798 0.49029511 0.48197177 0.07291053 0.95191823\n",
      " 0.04609983 0.70014381 0.41742758 0.85473668 0.25897085 0.8257759\n",
      " 0.83794593 0.81951887 0.24461911 0.84218333 0.34316071 0.49504455\n",
      " 0.7835552  0.84064851 0.82768072 0.27775559 0.68926315 0.80655087\n",
      " 0.39502335 0.95906385 0.0778516  0.8862848  0.34276554 0.76422279\n",
      " 0.03551227 0.39125055 0.4175035  0.9087698  0.35608909 0.240518\n",
      " 0.26720267 0.25059073 0.88072253 0.76385038 0.34671671 0.46787066\n",
      " 0.69473778 0.72413691 0.79996537 0.45132595 0.17948543 0.62103206\n",
      " 0.70368656 0.03022116 0.06278849 0.29323466 0.36982402 0.81992821\n",
      " 0.76812197 0.80535996 0.23351858 0.74224338 0.74232276 0.51147165\n",
      " 0.76932674 0.41224502 0.68357499 0.69766104 0.24855733 0.69991626\n",
      " 0.88622536 0.50356307 0.82594878 0.8145276  0.50843625 0.0072843\n",
      " 0.92631197 0.98435656 0.80214403 0.40562164 0.44159008 0.36550674\n",
      " 0.97586559 0.68304846 0.07930098 0.8962518  0.86500217 0.96085681\n",
      " 0.11573431 0.32161536 0.11112703 0.73157453 0.29828587 0.45381967\n",
      " 0.42059999 0.36871781 0.47374609 0.20250641 0.23810299 0.6099914\n",
      " 0.09554214 0.304646   0.44177949 0.8256086  0.87798653 0.00804519\n",
      " 0.29793594 0.32502977 0.36711367 0.80401192 0.95742676 0.39472832\n",
      " 0.72455847 0.78127887 0.35566344 0.7228758  0.82948056 0.0882634\n",
      " 0.72443861 0.48754858 0.85781379 0.31720941 0.88255487 0.66584316\n",
      " 0.88229894 0.01304447 0.89608897 0.39688762 0.83890859 0.33031137\n",
      " 0.36791654 0.14743435 0.40708962 0.81371264 0.43985235 0.70548785\n",
      " 0.04863185 0.01755388 0.48573261 0.94583678 0.73678527 0.18343859\n",
      " 0.38594229 0.85398525 0.60945631 0.40181809 0.18296612 0.54362059\n",
      " 0.90063093 0.69780973 0.84144247 0.10464281 0.85416481 0.30908355\n",
      " 0.40337594 0.77392337 0.49134048 0.76960954 0.79320478 0.76433622\n",
      " 0.84701907 0.20561723 0.27219998 0.33801419 0.84155452 0.57771715\n",
      " 0.02009726 0.48086155 0.23192998 0.51198085 0.14076028 0.41944331\n",
      " 0.50545267 0.42151946 0.         0.67158576 0.44919658 0.73685304\n",
      " 0.88076409 0.46941172 0.29880631 0.25525888 0.76256643 0.87221485\n",
      " 0.4079654  0.34087316 0.36717367 0.56353757 0.00136288 0.73727172\n",
      " 0.42458628 0.09401125 0.34915934 0.46952165]\n",
      "y_age_train: [0.94948417 0.2381668  0.32764812 1.         0.31766636 0.84368212\n",
      " 0.7595626  0.83501819 0.87988395 0.81880199 0.11055545 0.70780622\n",
      " 0.51792334 0.48900957 0.90513455 0.83050166 0.55074406 0.02658451\n",
      " 0.34506744 0.7742137  0.73334212 0.32664614 0.66485959 0.57613892\n",
      " 0.42518602 0.56120534 0.46221004 0.83964568 0.47029858 0.46121823\n",
      " 0.1409274  0.44231618 0.68955501 0.82086976 0.29167023 0.34921613\n",
      " 0.45431124 0.95220418 0.21034739 0.8108196  0.84065934 0.29830066\n",
      " 0.14731753 0.95133798 0.49029511 0.48197177 0.07291053 0.95191823\n",
      " 0.04609983 0.70014381 0.41742758 0.85473668 0.25897085 0.8257759\n",
      " 0.83794593 0.81951887 0.24461911 0.84218333 0.34316071 0.49504455\n",
      " 0.7835552  0.84064851 0.82768072 0.27775559 0.68926315 0.80655087\n",
      " 0.39502335 0.95906385 0.0778516  0.8862848  0.34276554 0.76422279\n",
      " 0.03551227 0.39125055 0.4175035  0.9087698  0.35608909 0.240518\n",
      " 0.26720267 0.25059073 0.88072253 0.76385038 0.34671671 0.46787066\n",
      " 0.69473778 0.72413691 0.79996537 0.45132595 0.17948543 0.62103206\n",
      " 0.70368656 0.03022116 0.06278849 0.29323466 0.36982402 0.81992821\n",
      " 0.76812197 0.80535996 0.23351858 0.74224338 0.74232276 0.51147165\n",
      " 0.76932674 0.41224502 0.68357499 0.69766104 0.24855733 0.69991626\n",
      " 0.88622536 0.50356307 0.82594878 0.8145276  0.50843625 0.0072843\n",
      " 0.92631197 0.98435656 0.80214403 0.40562164 0.44159008 0.36550674\n",
      " 0.97586559 0.68304846 0.07930098 0.8962518  0.86500217 0.96085681\n",
      " 0.11573431 0.32161536 0.11112703 0.73157453 0.29828587 0.45381967\n",
      " 0.42059999 0.36871781 0.47374609 0.20250641 0.23810299 0.6099914\n",
      " 0.09554214 0.304646   0.44177949 0.8256086  0.87798653 0.00804519\n",
      " 0.29793594 0.32502977 0.36711367 0.80401192 0.95742676 0.39472832\n",
      " 0.72455847 0.78127887 0.35566344 0.7228758  0.82948056 0.0882634\n",
      " 0.72443861 0.48754858 0.85781379 0.31720941 0.88255487 0.66584316\n",
      " 0.88229894 0.01304447 0.89608897 0.39688762 0.83890859 0.33031137\n",
      " 0.36791654 0.14743435 0.40708962 0.81371264 0.43985235 0.70548785\n",
      " 0.04863185 0.01755388 0.48573261 0.94583678 0.73678527 0.18343859\n",
      " 0.38594229 0.85398525 0.60945631 0.40181809 0.18296612 0.54362059\n",
      " 0.90063093 0.69780973 0.84144247 0.10464281 0.85416481 0.30908355\n",
      " 0.40337594 0.77392337 0.49134048 0.76960954 0.79320478 0.76433622\n",
      " 0.84701907 0.20561723 0.27219998 0.33801419 0.84155452 0.57771715\n",
      " 0.02009726 0.48086155 0.23192998 0.51198085 0.14076028 0.41944331\n",
      " 0.50545267 0.42151946 0.         0.67158576 0.44919658 0.73685304\n",
      " 0.88076409 0.46941172 0.29880631 0.25525888 0.76256643 0.87221485\n",
      " 0.4079654  0.34087316 0.36717367 0.56353757 0.00136288 0.73727172\n",
      " 0.42458628 0.09401125 0.34915934 0.46952165]\n"
     ]
    }
   ],
   "source": [
    "print('y_logteff_train:',y_logteff_train[0])\n",
    "print('y_logg_train:',y_logg_train[0])\n",
    "print('y_feh_train:',y_logg_train[0])\n",
    "print('y_age_train:',y_logg_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the StarNet model architecture**\n",
    "\n",
    "The StarNet architecture is built with:\n",
    "- input layer\n",
    "- 2 convolutional layers\n",
    "- 1 maxpooling layer followed by flattening for the fully connected layer\n",
    "- 2 fully connected layers\n",
    "- output layer\n",
    "\n",
    "First, let's define some model variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation function used following every layer except for the output layers\n",
    "activation = 'relu'\n",
    "#activation = 'sigmoid'\n",
    "\n",
    "# model weight initializer\n",
    "initializer = 'he_normal'\n",
    "\n",
    "# number of filters used in the convolutional layers\n",
    "#num_filters = [4,16]\n",
    "num_filters = [8,32]\n",
    "#num_filters = [8,16]\n",
    "\n",
    "# length of the filters in the convolutional layers\n",
    "#filter_length = 8\n",
    "#filter_length = 16\n",
    "filter_length = 8\n",
    "\n",
    "# length of the maxpooling window \n",
    "pool_length = 4\n",
    "\n",
    "# number of nodes in each of the hidden fully connected layers\n",
    "num_hidden = [256,128]\n",
    "#num_hidden = [24,12]\n",
    "\n",
    "# number of spectra fed into model at once during training\n",
    "batch_size = 64\n",
    "\n",
    "# maximum number of interations for model training\n",
    "#max_epochs = 200\n",
    "max_epochs = 100\n",
    "#max_epochs = 150 \n",
    "#max_epochs = 350\n",
    "#max_epochs = 225\n",
    "#max_epochs = 180\n",
    "#max_epochs = 450\n",
    "#max_epochs = 300\n",
    "#max_epochs = 1000\n",
    "\n",
    "\n",
    "# initial learning rate for optimization algorithm\n",
    "lr = 0.000003 #handled by Adam\n",
    "    \n",
    "# exponential decay rate for the 1st moment estimates for optimization algorithm\n",
    "beta_1 = 0.9\n",
    "\n",
    "# exponential decay rate for the 2nd moment estimates for optimization algorithm\n",
    "beta_2 = 0.999\n",
    "\n",
    "# a small constant for numerical stability for optimization algorithm\n",
    "optimizer_epsilon = 1e-08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of RVS fluxes= 1134\n",
      "number of BP fluxes= 33\n",
      "number of RP fluxes= 40\n",
      "number of training labels= 4\n"
     ]
    }
   ],
   "source": [
    "num_RVSfluxes=len(x_RVStrain[0,:]) \n",
    "print('number of RVS fluxes=', num_RVSfluxes)\n",
    "\n",
    "num_BPfluxes=len(x_BPtrain[0,:]) \n",
    "print('number of BP fluxes=', num_BPfluxes)\n",
    "\n",
    "num_RPfluxes=len(x_RPtrain[0,:]) \n",
    "print('number of RP fluxes=', num_RPfluxes)\n",
    "\n",
    "\n",
    "num_labels= 4\n",
    "print('number of training labels=', num_labels)\n",
    "\n",
    "#ilam = np.linspace(0, num_fluxes-1, num_fluxes)\n",
    "#plt.plot(ilam, x_train[329, :])\n",
    "#plt.plot()\n",
    "\n",
    "#iy = np.linspace(0, len(y_train)-1, len(y_train))\n",
    "#plt.plot(iy, y_train)\n",
    "#plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " num_RVSfluxes= 1134\n",
      " num_BPfluxes= 33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input RVS spectra\n",
    "print(' num_RVSfluxes=', num_RVSfluxes)\n",
    "input_RVSspec = Input(shape=(num_RVSfluxes,), name='rvs_input_x' ) #removed name='starnet_input_x'\n",
    "\n",
    "# Reshape spectra for RVS layers\n",
    "cur_rvs = Reshape((num_RVSfluxes, 1))(input_RVSspec)\n",
    "\n",
    "# CNN layers\n",
    "cur_rvs = Conv1D(kernel_initializer=initializer, activation=activation, \n",
    "                padding=\"same\", filters=num_filters[0], kernel_size=filter_length)(cur_rvs) #first CNN layer\n",
    "cur_rvs = Conv1D(kernel_initializer=initializer, activation=activation,\n",
    "                padding=\"same\", filters=num_filters[1], kernel_size=filter_length)(cur_rvs) #2nd CNN layer\n",
    "\n",
    "# Max pooling layer\n",
    "cur_rvs = MaxPooling1D(pool_size=pool_length)(cur_rvs)\n",
    "\n",
    "# Flatten the current input for the fully-connected layers\n",
    "cur_rvs = Flatten()(cur_rvs)\n",
    "\n",
    "\n",
    "##############################################################################################\n",
    "\n",
    "\n",
    "# Input BP spectra\n",
    "print(' num_BPfluxes=', num_BPfluxes)\n",
    "input_BPspec = Input(shape=(num_BPfluxes,), name='bp_input_x' ) #removed name='starnet_input_x'\n",
    "\n",
    "# Reshape spectra for BP layers\n",
    "cur_bp = Reshape((num_BPfluxes, 1))(input_BPspec)\n",
    "\n",
    "# CNN layers\n",
    "cur_bp = Conv1D(kernel_initializer=initializer, activation=activation, \n",
    "                padding=\"same\", filters=num_filters[0], kernel_size=filter_length)(cur_bp) #first CNN layer\n",
    "cur_bp = Conv1D(kernel_initializer=initializer, activation=activation,\n",
    "                padding=\"same\", filters=num_filters[1], kernel_size=filter_length)(cur_bp) #2nd CNN layer\n",
    "\n",
    "# Max pooling layer\n",
    "cur_bp = MaxPooling1D(pool_size=pool_length)(cur_bp)\n",
    "\n",
    "\n",
    "# Flatten the current input for the fully-connected layers\n",
    "cur_bp = Flatten()(cur_bp)\n",
    "\n",
    "\n",
    "################################################################################################\n",
    "\n",
    "# Input RP spectra\n",
    "input_RPspec = Input(shape=(num_RPfluxes,), name='rp_input_x' ) #removed name='starnet_input_x'\n",
    "\n",
    "# Reshape spectra for CNN layers\n",
    "cur_rp = Reshape((num_RPfluxes, 1))(input_RPspec)\n",
    "\n",
    "# CNN layers\n",
    "cur_rp = Conv1D(kernel_initializer=initializer, activation=activation, \n",
    "                padding=\"same\", filters=num_filters[0], kernel_size=filter_length)(cur_rp) #first CNN layer\n",
    "cur_rp = Conv1D(kernel_initializer=initializer, activation=activation,\n",
    "                padding=\"same\", filters=num_filters[1], kernel_size=filter_length)(cur_rp) #2nd CNN layer\n",
    "\n",
    "# Max pooling layer\n",
    "cur_rp = MaxPooling1D(pool_size=pool_length)(cur_rp)\n",
    "\n",
    "# Flatten the current input for the fully-connected layers\n",
    "cur_rp = Flatten()(cur_rp)\n",
    "\n",
    "###############################################################################################\n",
    "\n",
    "#concatenate RVS/BP/RP and then insert it to dense layer \n",
    "\n",
    "cur_comb = Concatenate()([cur_rvs, cur_bp, cur_rp])\n",
    "\n",
    "#cur_comb = cur_comb\n",
    "\n",
    "# Fully-connected layers\n",
    "cur_final = Dense(units=num_hidden[0], kernel_initializer=initializer, \n",
    "               activation=activation)(cur_comb)\n",
    "cur_final = Dense(units=num_hidden[1], kernel_initializer=initializer, \n",
    "               activation=activation)(cur_final)\n",
    "\n",
    "# Output nodes\n",
    "output_final = Dense(units=num_labels, activation=\"linear\", \n",
    "                    input_dim=num_hidden[1], name='output_y')(cur_final)\n",
    "\n",
    "\n",
    "model = Model(inputs = [input_RVSspec, input_BPspec, input_RPspec], outputs=output_final)\n",
    "\n",
    "#model = Model(inputs = [input_RPspec], outputs=output_final)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rvs_input_x (InputLayer)        [(None, 1134)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bp_input_x (InputLayer)         [(None, 33)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rp_input_x (InputLayer)         [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1134, 1)      0           rvs_input_x[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 33, 1)        0           bp_input_x[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 40, 1)        0           rp_input_x[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1134, 8)      72          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 33, 8)        72          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 40, 8)        72          reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1134, 32)     2080        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 33, 32)       2080        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 40, 32)       2080        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 283, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 8, 32)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 10, 32)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9056)         0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 320)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9632)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2466048     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_y (Dense)                (None, 4)            516         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,505,916\n",
      "Trainable params: 2,505,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More model techniques**\n",
    "* The `Adam` optimizer is the gradient descent algorithm used for minimizing the loss function\n",
    "* `EarlyStopping` uses the cross-validation set to test the model following every iteration and stops the training if the cv loss does not decrease by `min_delta` after `patience` iterations\n",
    "* `ReduceLROnPlateau` is a form of learning rate decay where the learning rate is decreased by a factor of `factor` if the training loss does not decrease by `epsilon` after `patience` iterations unless the learning rate has reached `min_lr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default loss function parameters\n",
    "early_stopping_min_delta = 0.0007\n",
    "early_stopping_patience = 4\n",
    "reduce_lr_factor = 0.5\n",
    "reduce_lr_epsilon = 0.0000009\n",
    "reduce_lr_patience = 2\n",
    "reduce_lr_min = 0.00008\n",
    "\n",
    "# loss function to minimize\n",
    "loss_function = 'mean_squared_error'\n",
    "\n",
    "# compute mean absolute deviation\n",
    "metrics = ['mae', 'mse']\n",
    "#metrics = ['mae']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    }
   ],
   "source": [
    "#optimizer = Adam(lr=lr, beta_1=beta_1, beta_2=beta_2, epsilon=optimizer_epsilon, decay=0.0)\n",
    "optimizer = Adam(lr=0.0001 )\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=early_stopping_min_delta, \n",
    "                                       patience=early_stopping_patience, verbose=2, mode='min')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, epsilon=reduce_lr_epsilon, \n",
    "                                  patience=reduce_lr_patience, min_lr=reduce_lr_min, mode='min', verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "rvs_input_x (InputLayer)        [(None, 1134)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bp_input_x (InputLayer)         [(None, 33)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rp_input_x (InputLayer)         [(None, 40)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 1134, 1)      0           rvs_input_x[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 33, 1)        0           bp_input_x[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 40, 1)        0           rp_input_x[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 1134, 8)      72          reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 33, 8)        72          reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 40, 8)        72          reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 1134, 32)     2080        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 33, 32)       2080        conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 40, 32)       2080        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 283, 32)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 8, 32)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 10, 32)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9056)         0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 256)          0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 320)          0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 9632)         0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          2466048     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "output_y (Dense)                (None, 4)            516         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,505,916\n",
      "Trainable params: 2,505,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the cv logteff and logg= (58, 4)\n",
      " shape of y teff and logg= (242, 4)\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1491dc8c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x1491dc8c8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "6/8 [=====================>........] - ETA: 0s - loss: 0.6001 - mae: 0.6600 - mse: 0.6001WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1492c1ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x1492c1ea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "8/8 [==============================] - 0s 47ms/step - loss: 0.4826 - mae: 0.5702 - mse: 0.4826 - val_loss: 0.1319 - val_mae: 0.3091 - val_mse: 0.1319\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1677 - mae: 0.3264 - mse: 0.1677 - val_loss: 0.1764 - val_mae: 0.3150 - val_mse: 0.1764\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1847 - mae: 0.3441 - mse: 0.1847 - val_loss: 0.1020 - val_mae: 0.2593 - val_mse: 0.1020\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1179 - mae: 0.2748 - mse: 0.1179 - val_loss: 0.1461 - val_mae: 0.3100 - val_mse: 0.1461\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1613 - mae: 0.3163 - mse: 0.1613 - val_loss: 0.1002 - val_mae: 0.2554 - val_mse: 0.1002\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1123 - mae: 0.2639 - mse: 0.1123 - val_loss: 0.1365 - val_mae: 0.3059 - val_mse: 0.1365\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1717 - mae: 0.3155 - mse: 0.1717 - val_loss: 0.1435 - val_mae: 0.3033 - val_mse: 0.1435\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1405 - mae: 0.3137 - mse: 0.1405 - val_loss: 0.1483 - val_mae: 0.3132 - val_mse: 0.1483\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1191 - mae: 0.2857 - mse: 0.1191 - val_loss: 0.1493 - val_mae: 0.3196 - val_mse: 0.1493\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1211 - mae: 0.2705 - mse: 0.1211 - val_loss: 0.1069 - val_mae: 0.2739 - val_mse: 0.1069\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1127 - mae: 0.2742 - mse: 0.1127 - val_loss: 0.1137 - val_mae: 0.2723 - val_mse: 0.1137\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1195 - mae: 0.2685 - mse: 0.1195 - val_loss: 0.2199 - val_mae: 0.3518 - val_mse: 0.2199\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1584 - mae: 0.3055 - mse: 0.1584 - val_loss: 0.1452 - val_mae: 0.2970 - val_mse: 0.1452\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1496 - mae: 0.3042 - mse: 0.1496 - val_loss: 0.1384 - val_mae: 0.3158 - val_mse: 0.1384\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1445 - mae: 0.3157 - mse: 0.1445 - val_loss: 0.1249 - val_mae: 0.2887 - val_mse: 0.1249\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1273 - mae: 0.2947 - mse: 0.1273 - val_loss: 0.1374 - val_mae: 0.3017 - val_mse: 0.1374\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1320 - mae: 0.2871 - mse: 0.1320 - val_loss: 0.1011 - val_mae: 0.2749 - val_mse: 0.1011\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1283 - mae: 0.2921 - mse: 0.1283 - val_loss: 0.1024 - val_mae: 0.2766 - val_mse: 0.1024\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1315 - mae: 0.2887 - mse: 0.1315 - val_loss: 0.1144 - val_mae: 0.2666 - val_mse: 0.1144\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1221 - mae: 0.2825 - mse: 0.1221 - val_loss: 0.1411 - val_mae: 0.3017 - val_mse: 0.1411\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1315 - mae: 0.2934 - mse: 0.1315 - val_loss: 0.1360 - val_mae: 0.3098 - val_mse: 0.1360\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1425 - mae: 0.3007 - mse: 0.1425 - val_loss: 0.1056 - val_mae: 0.2593 - val_mse: 0.1056\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1099 - mae: 0.2689 - mse: 0.1099 - val_loss: 0.1304 - val_mae: 0.2808 - val_mse: 0.1304\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1325 - mae: 0.2831 - mse: 0.1325 - val_loss: 0.1179 - val_mae: 0.2741 - val_mse: 0.1179\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1489 - mae: 0.3025 - mse: 0.1489 - val_loss: 0.0992 - val_mae: 0.2609 - val_mse: 0.0992\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1642 - mae: 0.3148 - mse: 0.1642 - val_loss: 0.1127 - val_mae: 0.2791 - val_mse: 0.1127\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1234 - mae: 0.2902 - mse: 0.1234 - val_loss: 0.1173 - val_mae: 0.2687 - val_mse: 0.1173\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1160 - mae: 0.2767 - mse: 0.1160 - val_loss: 0.0981 - val_mae: 0.2473 - val_mse: 0.0981\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1171 - mae: 0.2764 - mse: 0.1171 - val_loss: 0.0940 - val_mae: 0.2572 - val_mse: 0.0940\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1208 - mae: 0.2732 - mse: 0.1208 - val_loss: 0.0969 - val_mae: 0.2619 - val_mse: 0.0969\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1180 - mae: 0.2740 - mse: 0.1180 - val_loss: 0.1098 - val_mae: 0.2665 - val_mse: 0.1098\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1233 - mae: 0.2693 - mse: 0.1233 - val_loss: 0.1338 - val_mae: 0.2884 - val_mse: 0.1338\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0886 - mae: 0.2375 - mse: 0.0886 - val_loss: 0.1561 - val_mae: 0.3001 - val_mse: 0.1561\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1786 - mae: 0.3043 - mse: 0.1786 - val_loss: 0.2078 - val_mae: 0.3652 - val_mse: 0.2078\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1203 - mae: 0.2777 - mse: 0.1203 - val_loss: 0.1056 - val_mae: 0.2654 - val_mse: 0.1056\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1046 - mae: 0.2564 - mse: 0.1046 - val_loss: 0.0990 - val_mae: 0.2653 - val_mse: 0.0990\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1094 - mae: 0.2650 - mse: 0.1094 - val_loss: 0.1193 - val_mae: 0.2776 - val_mse: 0.1193\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1478 - mae: 0.2964 - mse: 0.1478 - val_loss: 0.1094 - val_mae: 0.2556 - val_mse: 0.1094\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1059 - mae: 0.2618 - mse: 0.1059 - val_loss: 0.1338 - val_mae: 0.2936 - val_mse: 0.1338\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1429 - mae: 0.2905 - mse: 0.1429 - val_loss: 0.1051 - val_mae: 0.2564 - val_mse: 0.1051\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1018 - mae: 0.2575 - mse: 0.1018 - val_loss: 0.0884 - val_mae: 0.2458 - val_mse: 0.0884\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0971 - mae: 0.2576 - mse: 0.0971 - val_loss: 0.1005 - val_mae: 0.2615 - val_mse: 0.1005\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1132 - mae: 0.2661 - mse: 0.1132 - val_loss: 0.0878 - val_mae: 0.2462 - val_mse: 0.0878\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0889 - mae: 0.2420 - mse: 0.0889 - val_loss: 0.1744 - val_mae: 0.3078 - val_mse: 0.1744\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1286 - mae: 0.2644 - mse: 0.1286 - val_loss: 0.1803 - val_mae: 0.3115 - val_mse: 0.1803\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1743 - mae: 0.3097 - mse: 0.1743 - val_loss: 0.2647 - val_mae: 0.4000 - val_mse: 0.2647\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1515 - mae: 0.2991 - mse: 0.1515 - val_loss: 0.1561 - val_mae: 0.2848 - val_mse: 0.1561\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1715 - mae: 0.3175 - mse: 0.1715 - val_loss: 0.1285 - val_mae: 0.3028 - val_mse: 0.1285\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1266 - mae: 0.2870 - mse: 0.1266 - val_loss: 0.1015 - val_mae: 0.2541 - val_mse: 0.1015\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1008 - mae: 0.2636 - mse: 0.1008 - val_loss: 0.0932 - val_mae: 0.2480 - val_mse: 0.0932\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.0988 - mae: 0.2498 - mse: 0.0988 - val_loss: 0.0956 - val_mae: 0.2541 - val_mse: 0.0956\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1019 - mae: 0.2617 - mse: 0.1019 - val_loss: 0.0877 - val_mae: 0.2488 - val_mse: 0.0877\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1313 - mae: 0.2922 - mse: 0.1313 - val_loss: 0.1269 - val_mae: 0.2768 - val_mse: 0.1269\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1469 - mae: 0.3051 - mse: 0.1469 - val_loss: 0.1640 - val_mae: 0.3251 - val_mse: 0.1640\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1726 - mae: 0.3359 - mse: 0.1726 - val_loss: 0.1101 - val_mae: 0.2825 - val_mse: 0.1101\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1392 - mae: 0.3041 - mse: 0.1392 - val_loss: 0.1077 - val_mae: 0.2736 - val_mse: 0.1077\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1906 - mae: 0.3424 - mse: 0.1906 - val_loss: 0.1616 - val_mae: 0.3122 - val_mse: 0.1616\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1887 - mae: 0.3363 - mse: 0.1887 - val_loss: 0.2262 - val_mae: 0.3662 - val_mse: 0.2262\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1649 - mae: 0.3148 - mse: 0.1649 - val_loss: 0.1229 - val_mae: 0.2569 - val_mse: 0.1229\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1482 - mae: 0.2938 - mse: 0.1482 - val_loss: 0.1821 - val_mae: 0.3570 - val_mse: 0.1821\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1458 - mae: 0.3061 - mse: 0.1458 - val_loss: 0.1270 - val_mae: 0.2895 - val_mse: 0.1270\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 31ms/step - loss: 0.1258 - mae: 0.2953 - mse: 0.1258 - val_loss: 0.1207 - val_mae: 0.2975 - val_mse: 0.1207\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 0.1161 - mae: 0.2638 - mse: 0.1161 - val_loss: 0.1193 - val_mae: 0.2706 - val_mse: 0.1193\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0927 - mae: 0.2493 - mse: 0.0927 - val_loss: 0.1620 - val_mae: 0.3205 - val_mse: 0.1620\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1003 - mae: 0.2587 - mse: 0.1003 - val_loss: 0.1126 - val_mae: 0.2763 - val_mse: 0.1126\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1052 - mae: 0.2652 - mse: 0.1052 - val_loss: 0.1184 - val_mae: 0.2767 - val_mse: 0.1184\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1261 - mae: 0.2866 - mse: 0.1261 - val_loss: 0.0928 - val_mae: 0.2497 - val_mse: 0.0928\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1277 - mae: 0.2885 - mse: 0.1277 - val_loss: 0.1343 - val_mae: 0.3123 - val_mse: 0.1343\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1645 - mae: 0.3388 - mse: 0.1645 - val_loss: 0.1640 - val_mae: 0.3338 - val_mse: 0.1640\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1196 - mae: 0.2825 - mse: 0.1196 - val_loss: 0.1046 - val_mae: 0.2786 - val_mse: 0.1046\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1044 - mae: 0.2620 - mse: 0.1044 - val_loss: 0.0952 - val_mae: 0.2585 - val_mse: 0.0952\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.1039 - mae: 0.2622 - mse: 0.1039 - val_loss: 0.0936 - val_mae: 0.2485 - val_mse: 0.0936\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1015 - mae: 0.2578 - mse: 0.1015 - val_loss: 0.1252 - val_mae: 0.2945 - val_mse: 0.1252\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1038 - mae: 0.2662 - mse: 0.1038 - val_loss: 0.1023 - val_mae: 0.2539 - val_mse: 0.1023\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1084 - mae: 0.2634 - mse: 0.1084 - val_loss: 0.1243 - val_mae: 0.2933 - val_mse: 0.1243\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1201 - mae: 0.2707 - mse: 0.1201 - val_loss: 0.1076 - val_mae: 0.2633 - val_mse: 0.1076\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0822 - mae: 0.2320 - mse: 0.0822 - val_loss: 0.1324 - val_mae: 0.3032 - val_mse: 0.1324\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1036 - mae: 0.2561 - mse: 0.1036 - val_loss: 0.1060 - val_mae: 0.2708 - val_mse: 0.1060\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1151 - mae: 0.2708 - mse: 0.1151 - val_loss: 0.1030 - val_mae: 0.2520 - val_mse: 0.1030\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0914 - mae: 0.2525 - mse: 0.0914 - val_loss: 0.1242 - val_mae: 0.2862 - val_mse: 0.1242\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1107 - mae: 0.2637 - mse: 0.1107 - val_loss: 0.1061 - val_mae: 0.2746 - val_mse: 0.1061\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1114 - mae: 0.2729 - mse: 0.1114 - val_loss: 0.1085 - val_mae: 0.2639 - val_mse: 0.1085\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0991 - mae: 0.2550 - mse: 0.0991 - val_loss: 0.1007 - val_mae: 0.2607 - val_mse: 0.1007\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0956 - mae: 0.2538 - mse: 0.0956 - val_loss: 0.1049 - val_mae: 0.2646 - val_mse: 0.1049\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1099 - mae: 0.2709 - mse: 0.1099 - val_loss: 0.1049 - val_mae: 0.2633 - val_mse: 0.1049\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0960 - mae: 0.2475 - mse: 0.0960 - val_loss: 0.1072 - val_mae: 0.2796 - val_mse: 0.1072\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1141 - mae: 0.2720 - mse: 0.1141 - val_loss: 0.1000 - val_mae: 0.2505 - val_mse: 0.1000\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1189 - mae: 0.2690 - mse: 0.1189 - val_loss: 0.1292 - val_mae: 0.3031 - val_mse: 0.1292\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 29ms/step - loss: 0.1252 - mae: 0.2925 - mse: 0.1252 - val_loss: 0.1177 - val_mae: 0.2785 - val_mse: 0.1177\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1109 - mae: 0.2732 - mse: 0.1109 - val_loss: 0.1225 - val_mae: 0.3010 - val_mse: 0.1225\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.1010 - mae: 0.2565 - mse: 0.1010 - val_loss: 0.1006 - val_mae: 0.2506 - val_mse: 0.1006\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0987 - mae: 0.2559 - mse: 0.0987 - val_loss: 0.0953 - val_mae: 0.2573 - val_mse: 0.0953\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0978 - mae: 0.2555 - mse: 0.0978 - val_loss: 0.0976 - val_mae: 0.2476 - val_mse: 0.0976\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1143 - mae: 0.2675 - mse: 0.1143 - val_loss: 0.1358 - val_mae: 0.3101 - val_mse: 0.1358\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1326 - mae: 0.2888 - mse: 0.1326 - val_loss: 0.1265 - val_mae: 0.2917 - val_mse: 0.1265\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1215 - mae: 0.2766 - mse: 0.1215 - val_loss: 0.1395 - val_mae: 0.3207 - val_mse: 0.1395\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1058 - mae: 0.2690 - mse: 0.1058 - val_loss: 0.1069 - val_mae: 0.2651 - val_mse: 0.1069\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0989 - mae: 0.2554 - mse: 0.0989 - val_loss: 0.1154 - val_mae: 0.2885 - val_mse: 0.1154\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0945 - mae: 0.2540 - mse: 0.0945 - val_loss: 0.0884 - val_mae: 0.2409 - val_mse: 0.0884\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1080 - mae: 0.2605 - mse: 0.1080 - val_loss: 0.1084 - val_mae: 0.2665 - val_mse: 0.1084\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#history = model.fit(x_train, y_train, validation_data=(x_cv, y_cv),\n",
    "          #epochs=max_epochs, verbose=1, shuffle='batch',\n",
    "         #callbacks=[early_stopping, reduce_lr])\n",
    "        \n",
    "\n",
    "y_train_stack = np.column_stack((y_logteff_train[0], y_logg_train[0], y_feh_train[0], y_age_train[0]))\n",
    "y_cv_stack = np.column_stack ((y_logteff_cv[0], y_logg_cv[0], y_feh_cv[0], y_age_cv[0]))\n",
    "\n",
    "print('shape of the cv logteff and logg=', np.shape(y_cv_stack))\n",
    "print(' shape of y teff and logg=', np.shape(y_train_stack))\n",
    "                                \n",
    "#history = model.fit(x=[x_RVStrain, x_BPtrain, x_RPtrain], y=y_train_stack,\n",
    "          #validation_split=0.2, epochs=max_epochs, verbose=1, shuffle='batch')\n",
    "        \n",
    "#history = model.fit(x=[x_RVStrain, x_BPtrain, x_RPtrain], y= y_train_stack, \n",
    "                    #validation_data=([x_RVScv, x_BPcv, x_RPcv], y_cv_stack),\n",
    "          #epochs=max_epochs, verbose=1, shuffle='batch')\n",
    "\n",
    "history = model.fit(x=[ x_RVStrain, x_BPtrain, x_RPtrain], y= y_train_stack, \n",
    "                    validation_data=([x_RVScv, x_BPcv, x_RPcv], y_cv_stack),\n",
    "          epochs=max_epochs, verbose=1, shuffle='batch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "hist['epoch']= history.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    plt.figure(figsize=(13,9))\n",
    "    #plt.figure()\n",
    "    plt.xlabel('Epoch', fontsize= 18)\n",
    "    plt.ylabel('Mean Abs Error', fontsize= 18)\n",
    "    plt.plot(hist['epoch'], hist['mae'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'], label = 'Val Error')\n",
    "    plt.ylim([0,1.2])\n",
    "    plt.tick_params(labelsize=20)\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(13,9))\n",
    "    #plt.figure()\n",
    "    plt.xlabel('Epoch', fontsize = 20)\n",
    "    plt.ylabel('Mean Square Error', fontsize= 20)\n",
    "    plt.plot(hist['epoch'], hist['mse'], label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'], label = 'Val Error')\n",
    "    plt.ylim([0,10])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnormalizing the labels (teff)\n",
    "\n",
    "print(np.shape(y_train_stack[:,0]))\n",
    "print(np.shape(y_train_stack[:,1]))\n",
    "print(np.shape(y_train_stack[:,2]))\n",
    "print(np.shape(y_train_stack[:,3]))\n",
    "\n",
    "\n",
    "\n",
    "def denormalize (labels, max_labels, min_labels):\n",
    "    denorm_labels = ((labels * (max_labels - min_labels)) + min_labels)\n",
    "    return (denorm_labels)\n",
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "test_predictions = model.predict([x_RVStrain, x_BPtrain, x_RPtrain])\n",
    "#test_predictions = model.predict([x_RPtrain])\n",
    "print('shape of test_predictions:',np.shape(test_predictions))\n",
    "print('print 10 elements of test_predictions:', test_predictions[0:10])\n",
    "plt.scatter(denormalize(y_train_stack[:,0], y_logteff_train[1], y_logteff_train[2] ), denormalize(test_predictions[:,0], y_logteff_train[1], y_logteff_train[2]), s= 4.0, c= 'r', label='LogTeff' )\n",
    "plt.scatter(denormalize(y_train_stack[:,1], y_logg_train[1], y_logg_train[2]), denormalize(test_predictions[:,1], y_logg_train[1], y_logg_train[2]), s= 4.0, c= 'b', label='Log(g)' )\n",
    "plt.scatter(denormalize(y_train_stack[:,2], y_feh_train[1], y_feh_train[2]), denormalize(test_predictions[:,2], y_feh_train[1], y_feh_train[2]), s= 4.0, c= 'k', label='[Fe/H]' )\n",
    "plt.scatter(denormalize(y_train_stack[:,3], y_age_train[1], y_age_train[2]), denormalize(test_predictions[:,3],  y_age_train[1], y_age_train[2]), s= 4.0, c= 'y', label='age' )\n",
    "plt.xlabel(r\"True\", fontsize=25)\n",
    "plt.ylabel(r\"Prediction\", fontsize=25)\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize= 25) \n",
    "#plt.xlim([0,plt.xlim()[1]])\n",
    "#plt.ylim([0,plt.ylim()[1]])\n",
    "#_ = plt.plot([-2, 3], [-2, 3], color='green')\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "print('fe/h denormalized:', denormalize(y_train_stack[:,2], y_feh_train[1], y_feh_train[2]))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the histogram of denormalized training set \n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "data_teff = np.subtract(denormalize(y_train_stack[:,0], y_logteff_train[1], y_logteff_train[2]), \n",
    "                        denormalize(test_predictions[:,0], y_logteff_train[1], y_logteff_train[2])) \n",
    "data_logg = np.subtract(denormalize(y_train_stack[:,1], y_logg_train[1], y_logg_train[2]), \n",
    "                       denormalize(test_predictions[:,1], y_logg_train[1], y_logg_train[2])) \n",
    "data_feh=np.subtract(denormalize(y_train_stack[:,2], y_feh_train[1], y_feh_train[2]),\n",
    "                      denormalize(test_predictions[:,2], y_feh_train[1], y_feh_train[2])) \n",
    "data_age=np.subtract(denormalize(y_train_stack[:,3], y_age_train[1], y_age_train[2]), \n",
    "                       denormalize(test_predictions[:,3],  y_age_train[1], y_age_train[2])) \n",
    "\n",
    "\n",
    "\n",
    "counts_teff, bins_teff = np.histogram(data_teff)\n",
    "counts_logg, bins_logg = np.histogram(data_logg)\n",
    "counts_feh, bins_feh = np.histogram(data_feh)\n",
    "counts_age, bins_age = np.histogram(data_age)\n",
    "\n",
    "\n",
    "#histogram for LogTeff\n",
    "plt.hist(bins_teff[:-1], bins_teff, weights=counts_teff, label= r'$\\rm log(\\rm T_{\\rm eff})$')\n",
    "plt.tick_params(labelsize=18) \n",
    "plt.xlabel(r'[Prediction-True]', fontsize=18)\n",
    "plt.ylabel('Counts', fontsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "#histogram for Log(g)\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.hist(bins_logg[:-1], bins_logg, weights=counts_logg, label= 'log(g)', color='red')\n",
    "plt.tick_params(labelsize=18) \n",
    "plt.xlabel(r'[Prediction-True]', fontsize=18)\n",
    "plt.ylabel('Counts', fontsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "#histogram for [Fe/H]\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.hist(bins_feh[:-1], bins_feh, weights=counts_feh, label= '[Fe/H]', color='magenta')\n",
    "plt.tick_params(labelsize=18) \n",
    "plt.xlabel(r'[Prediction-True]', fontsize=18)\n",
    "plt.ylabel('Counts', fontsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "#histogram for age\n",
    "plt.figure(figsize=(10,9))\n",
    "plt.hist(bins_age[:-1], bins_age, weights=counts_age, label= 'age', color='orange')\n",
    "plt.tick_params(labelsize=18) \n",
    "plt.xlabel(r'[Prediction-True]', fontsize=18)\n",
    "plt.ylabel('Counts', fontsize=18)\n",
    "plt.legend(fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print('standard deviation', len(z))\n",
    "#print(len(z[teff<5000]))\n",
    "#print(len(z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting deviation in Teff bins\n",
    "nbin = 6\n",
    "teffbin_edges=np.array([3.3, 3.5, 3.7, 4.1, 4.3, 4.5])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "teff_pred = denormalize(test_predictions[:,0], y_logteff_train[1], y_logteff_train[2])\n",
    "teff_true = denormalize(y_train_stack[:,0],  y_logteff_train[1], y_logteff_train[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "teff_diff = teff_pred-teff_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "teff_diff_mean = np.zeros(nbin) \n",
    "teff_diff_std = np.zeros(nbin)\n",
    "teffbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(teff_true<teffbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(teff_true>teffbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((teff_true>teffbin_edges[i-1]) & (teff_true<teffbin_edges[i]))\n",
    "        #if i=1, teff_true>(teffbin_edges[1-1=0]= 5000) & teff_true<teffbin_edges[1]= 10000, so 5000<teff<10000\n",
    "        #if i=2, teff_true>(teffbin_edges[2-1=1]=10000) & teff_true<teffbin_edges[2]= 15000, so 10000<teff<15000\n",
    "        #if i=3, teff_true> (teffbin_edges[3-1=2]= 15000) & teff_true<teffbin_edges[3]= 20000 so 15000<teff<20000\n",
    "    teffbin_mean[i] = np.mean(teff_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    teff_diff_mean[i] = np.mean(teff_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    teff_diff_std[i] = np.std(teff_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin teff_true=', teffbin_mean)\n",
    "print('mean of teff_diff=', teff_diff_mean)\n",
    "print('std of teff_diff=', teff_diff_std)\n",
    "print('length of teff_diff=', len(teff_diff))\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in Teff bins\n",
    "nbin = 6\n",
    "loggbin_edges=np.array([ 0., 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "logg_pred = denormalize(test_predictions[:,1], y_logg_train[1], y_logg_train[2])\n",
    "logg_true = denormalize(y_train_stack[:,1], y_logg_train[1], y_logg_train[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "logg_diff = logg_pred-logg_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "logg_diff_mean = np.zeros(nbin) \n",
    "logg_diff_std = np.zeros(nbin)\n",
    "loggbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(logg_true<loggbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(logg_true>loggbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((logg_true>loggbin_edges[i-1]) & (logg_true<loggbin_edges[i]))\n",
    "\n",
    "    loggbin_mean[i] = np.mean(logg_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    logg_diff_mean[i] = np.mean(logg_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    logg_diff_std[i] = np.std(logg_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin logg_true=', loggbin_mean)\n",
    "print('mean of logg_diff=', logg_diff_mean)\n",
    "print('std of logg_diff=', logg_diff_std)\n",
    "print('length of logg_diff=', len(logg_diff))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in feh bins\n",
    "nbin = 3\n",
    "fehbin_edges=np.array([-0.4, 0., 0.4])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "feh_pred = denormalize(test_predictions[:,2], y_feh_train[1], y_feh_train[2])\n",
    "feh_true = denormalize(y_train_stack[:,2], y_feh_train[1], y_feh_train[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "feh_diff = feh_pred-feh_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "feh_diff_mean = np.zeros(nbin) \n",
    "feh_diff_std = np.zeros(nbin)\n",
    "fehbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(feh_true<fehbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(feh_true>fehbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((feh_true>fehbin_edges[i-1]) & (feh_true<fehbin_edges[i]))\n",
    "\n",
    "    fehbin_mean[i] = np.mean(feh_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    feh_diff_mean[i] = np.mean(feh_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    feh_diff_std[i] = np.std(feh_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin feh_true=', fehbin_mean)\n",
    "print('mean of feh_diff=', feh_diff_mean)\n",
    "print('std of feh_diff=', feh_diff_std)\n",
    "print('length of feh_diff=', len(feh_diff))\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in age bins\n",
    "nbin = 6\n",
    "agebin_edges=np.array([5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "age_pred = denormalize(test_predictions[:,3], y_age_train[1], y_age_train[2])\n",
    "age_true = denormalize(y_train_stack[:,3], y_age_train[1], y_age_train[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "age_diff = feh_pred-feh_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "age_diff_mean = np.zeros(nbin) \n",
    "age_diff_std = np.zeros(nbin)\n",
    "agebin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(age_true<agebin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(age_true>agebin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((age_true>agebin_edges[i-1]) & (age_true<agebin_edges[i]))\n",
    "\n",
    "    agebin_mean[i] = np.mean(age_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    age_diff_mean[i] = np.mean(age_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    age_diff_std[i] = np.std(age_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin age_true=', agebin_mean)\n",
    "print('mean of age_diff=', age_diff_mean)\n",
    "print('std of age_diff=', age_diff_std)\n",
    "print('length of age_diff=', len(age_diff))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of logteff\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(teff_true, teff_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(teffbin_mean,teff_diff_mean, yerr=teff_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "plt.ylabel(r\"$T_{\\rm eff,pred}-T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([3.3, 4.5])\n",
    "ylim=np.array([-0.05,0.05])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm logT_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm logT_{\\rm eff,pred}-\\rm logT_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot log \n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(logg_true, logg_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(loggbin_mean,logg_diff_mean, yerr=logg_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "# set x, y label. \n",
    "#plt.xlabel(r\"$T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "#plt.ylabel(r\"$T_{\\rm eff,pred}-T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([-0.5, 5.5])\n",
    "ylim=np.array([-0.4,0.4])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm log(g)_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm log(g)_{\\rm pred}-\\rm log(g)_{\\rm true}$\", fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of feh\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(feh_true, feh_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(fehbin_mean, feh_diff_mean, yerr=feh_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([-0.5, 0.5])\n",
    "ylim=np.array([-0.1, 0.1])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm [Fe/H]_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm [Fe/H]_{\\rm pred}-\\rm [Fe/H]_{\\rm true}$ \", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of age\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(age_true, age_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(agebin_mean, age_diff_mean, yerr=age_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([5, 10.5])\n",
    "ylim=np.array([-0.1,0.1])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm age_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm age_{\\rm pred}-\\rm age_{\\rm true}$ \", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "plt.scatter(np.power(10, age_true-9.0), np.power(10, age_pred-9.0), s= 70)\n",
    "#plt.scatter( age_true,  age_pred, s= 70)\n",
    "plt.xlabel(r\"$\\rm age_{\\rm true}\\rm(Gyr)$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm age_{\\rm pred}\\rm(Gyr)$\", fontsize=18)\n",
    "\n",
    "plt.tick_params(labelsize=18)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "marker_size = 70\n",
    "plt.scatter(teff_true, logg_true, s= marker_size, c= np.power(10, age_diff-9.0), cmap ='jet' )\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.xlabel('log(Teff)', fontsize=18)\n",
    "plt.ylabel('log(g)', fontsize=18)\n",
    "plt.axis([4.5, 3.3, 6, -0.5])\n",
    "cbar= plt.colorbar()\n",
    "cbar.set_label(r\"($\\rm age_{\\rm pred}-\\rm age_{\\rm true})$\" , labelpad=+1, fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test set (x_cv)\n",
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "cv_predictions = model.predict([x_RVScv, x_BPcv, x_RPcv])\n",
    "#cv_predictions = model.predict([x_RPcv])\n",
    "print(np.shape(cv_predictions))\n",
    "\n",
    "print(np.shape(y_cv_stack[:,0]))\n",
    "print(np.shape(y_cv_stack[:,1]))\n",
    "print(np.shape(y_cv_stack[:,2]))\n",
    "print(np.shape(y_cv_stack[:,3]))\n",
    "\n",
    "\n",
    "\n",
    "#test_predictions = model.predict([x_RPtrain])\n",
    "print('shape of cv_predictions:',np.shape(cv_predictions))\n",
    "print('print 10 elements of test_predictions:', cv_predictions[0:10])\n",
    "plt.scatter(denormalize(y_cv_stack[:,0], y_logteff_cv[1], y_logteff_cv[2] ), denormalize(cv_predictions[:,0], y_logteff_cv[1], y_logteff_cv[2]), s= 4.0, c= 'r', label='LogTeff' )\n",
    "plt.scatter(denormalize(y_cv_stack[:,1], y_logg_cv[1], y_logg_cv[2]), denormalize(cv_predictions[:,1], y_logg_cv[1], y_logg_cv[2]), s= 4.0, c= 'b', label='Log(g)' )\n",
    "plt.scatter(denormalize(y_cv_stack[:,2], y_feh_cv[1], y_feh_cv[2]), denormalize(cv_predictions[:,2], y_feh_cv[1], y_feh_cv[2]), s= 4.0, c= 'k', label='[Fe/H]' )\n",
    "plt.scatter(denormalize(y_cv_stack[:,3], y_age_cv[1], y_age_cv[2]), denormalize(cv_predictions[:,3],  y_age_cv[1], y_age_cv[2]), s= 4.0, c= 'y', label='age' )\n",
    "plt.xlabel(r\"True\", fontsize=25)\n",
    "plt.ylabel(r\"Prediction\", fontsize=25)\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize= 25) \n",
    "#plt.xlim([0,plt.xlim()[1]])\n",
    "#plt.ylim([0,plt.ylim()[1]])\n",
    "#_ = plt.plot([-2, 3], [-2, 3], color='green')\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "#print('fe/h denormalized:', denormalize(y_train_cv[:,2], y_feh_cv[1], y_feh_cv[2]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting deviation in Teff bins\n",
    "nbin = 6\n",
    "teffbin_edges=np.array([3.3, 3.5, 3.7, 4.1, 4.3, 4.5])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "teff_pred = denormalize(cv_predictions[:,0], y_logteff_cv[1], y_logteff_cv[2])\n",
    "teff_true = denormalize(y_cv_stack[:,0],  y_logteff_cv[1], y_logteff_cv[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "teff_diff = teff_pred-teff_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "teff_diff_mean = np.zeros(nbin) \n",
    "teff_diff_std = np.zeros(nbin)\n",
    "teffbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(teff_true<teffbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(teff_true>teffbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((teff_true>teffbin_edges[i-1]) & (teff_true<teffbin_edges[i]))\n",
    "        #if i=1, teff_true>(teffbin_edges[1-1=0]= 5000) & teff_true<teffbin_edges[1]= 10000, so 5000<teff<10000\n",
    "        #if i=2, teff_true>(teffbin_edges[2-1=1]=10000) & teff_true<teffbin_edges[2]= 15000, so 10000<teff<15000\n",
    "        #if i=3, teff_true> (teffbin_edges[3-1=2]= 15000) & teff_true<teffbin_edges[3]= 20000 so 15000<teff<20000\n",
    "    teffbin_mean[i] = np.mean(teff_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    teff_diff_mean[i] = np.mean(teff_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    teff_diff_std[i] = np.std(teff_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin teff_true=', teffbin_mean)\n",
    "print('mean of teff_diff=', teff_diff_mean)\n",
    "print('std of teff_diff=', teff_diff_std)\n",
    "print('length of teff_diff=', len(teff_diff))\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in Teff bins\n",
    "nbin = 6\n",
    "loggbin_edges=np.array([ 0., 1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "logg_pred = denormalize(cv_predictions[:,1], y_logg_cv[1], y_logg_cv[2])\n",
    "logg_true = denormalize(y_cv_stack[:,1], y_logg_cv[1], y_logg_cv[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "logg_diff = logg_pred-logg_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "logg_diff_mean = np.zeros(nbin) \n",
    "logg_diff_std = np.zeros(nbin)\n",
    "loggbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(logg_true<loggbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(logg_true>loggbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((logg_true>loggbin_edges[i-1]) & (logg_true<loggbin_edges[i]))\n",
    "\n",
    "    loggbin_mean[i] = np.mean(logg_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    logg_diff_mean[i] = np.mean(logg_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    logg_diff_std[i] = np.std(logg_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin logg_true=', loggbin_mean)\n",
    "print('mean of logg_diff=', logg_diff_mean)\n",
    "print('std of logg_diff=', logg_diff_std)\n",
    "print('length of logg_diff=', len(logg_diff))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in feh bins\n",
    "nbin = 3\n",
    "fehbin_edges=np.array([-0.4, 0., 0.4])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "feh_pred = denormalize(cv_predictions[:,2], y_feh_cv[1], y_feh_cv[2])\n",
    "feh_true = denormalize(y_cv_stack[:,2], y_feh_cv[1], y_feh_cv[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "feh_diff = feh_pred-feh_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "feh_diff_mean = np.zeros(nbin) \n",
    "feh_diff_std = np.zeros(nbin)\n",
    "fehbin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(feh_true<fehbin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(feh_true>fehbin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((feh_true>fehbin_edges[i-1]) & (feh_true<fehbin_edges[i]))\n",
    "\n",
    "    fehbin_mean[i] = np.mean(feh_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    feh_diff_mean[i] = np.mean(feh_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    feh_diff_std[i] = np.std(feh_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin feh_true=', fehbin_mean)\n",
    "print('mean of feh_diff=', feh_diff_mean)\n",
    "print('std of feh_diff=', feh_diff_std)\n",
    "print('length of feh_diff=', len(feh_diff))\n",
    "\n",
    "####################################################################################################################\n",
    "print('=================================================================================================')\n",
    "# getting deviation in age bins\n",
    "nbin = 6\n",
    "agebin_edges=np.array([5, 6, 7, 8, 9, 10])\n",
    "\n",
    "# pred vs. true\n",
    "# unnormalised values\n",
    "age_pred = denormalize(cv_predictions[:,3], y_age_cv[1], y_age_cv[2])\n",
    "age_true = denormalize(y_cv_stack[:,3], y_age_cv[1], y_age_cv[2]) #teff values are created by read_spectra1_updatedwavelength from the nsc Allende Prieto spectra library\n",
    "age_diff = feh_pred-feh_true\n",
    "\n",
    "# compute mean and std in Teff bins\n",
    "age_diff_mean = np.zeros(nbin) \n",
    "age_diff_std = np.zeros(nbin)\n",
    "agebin_mean = np.zeros(nbin)\n",
    "\n",
    "for i in range(nbin): #iterations(0,1,2,3,4)\n",
    "    if i==0:\n",
    "        indx = np.where(age_true<agebin_edges[i]) #index of teff_true where teff true< 5000 since teff has all values of teff in each library\n",
    "        #print(indx)\n",
    "    elif i==nbin-1: #if i= 5-1= 4\n",
    "        indx = np.where(age_true>agebin_edges[i-1]) #index of true_teff>20000\n",
    "    else: #if i=1,2,3\n",
    "        indx = np.where((age_true>agebin_edges[i-1]) & (age_true<agebin_edges[i]))\n",
    "\n",
    "    agebin_mean[i] = np.mean(age_true[indx]) #calculating the mean values of teff_true from assigning its index in the for loop\n",
    "    age_diff_mean[i] = np.mean(age_diff[indx]) #calculating the mean values of teff_diff from its index \n",
    "    age_diff_std[i] = np.std(age_diff[indx]) #calculating the std values of teff-diff from its index\n",
    "    \n",
    "print('mean of bin age_true=', agebin_mean)\n",
    "print('mean of age_diff=', age_diff_mean)\n",
    "print('std of age_diff=', age_diff_std)\n",
    "print('length of age_diff=', len(age_diff))\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of logteff\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(teff_true, teff_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(teffbin_mean,teff_diff_mean, yerr=teff_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "plt.ylabel(r\"$T_{\\rm eff,pred}-T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([3.3, 4.5])\n",
    "ylim=np.array([-0.065,0.065])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm logT_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm logT_{\\rm eff,pred}-\\rm logT_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot log \n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(logg_true, logg_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(loggbin_mean,logg_diff_mean, yerr=logg_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "# set x, y label. \n",
    "#plt.xlabel(r\"$T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "#plt.ylabel(r\"$T_{\\rm eff,pred}-T_{\\rm eff,true}$ (K)\", fontsize=18)\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([-0.5, 5.5])\n",
    "ylim=np.array([-0.6,0.6])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm log(g)_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm log(g)_{\\rm pred}-\\rm log(g)_{\\rm true}$\", fontsize=18)\n",
    "\n",
    "\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of feh\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(feh_true, feh_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(fehbin_mean, feh_diff_mean, yerr=feh_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([-0.5, 0.5])\n",
    "ylim=np.array([-0.3, 0.3])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm [Fe/H]_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm [Fe/H]_{\\rm pred}-\\rm [Fe/H]_{\\rm true}$ \", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot of age\n",
    "plt.figure(figsize=(13,9))\n",
    "# plot the difference\n",
    "plt.scatter(age_true, age_diff ,c='k', marker='.')\n",
    "#plt.plot(teff_true, teff_diff,'o', markersize=1, c='k')\n",
    "\n",
    "# plot mean (symbol) and scatter with error bars\n",
    "plt.errorbar(agebin_mean, age_diff_mean, yerr=age_diff_std, fmt='-o', c='r',capsize=3) #plotting the teff bin mean in x-axis and teff_diff in y-axis\n",
    "\n",
    "# increase the x,y tick label size\n",
    "plt.tick_params(labelsize=18) \n",
    "\n",
    "\n",
    "\n",
    "# set x, y lim plot range\n",
    "xlim=np.array([4.5, 10.5])\n",
    "ylim=np.array([-0.3,0.3])\n",
    "plt.xlim(xlim[0],xlim[1]) #plotting the xlim\n",
    "plt.ylim(ylim[0],ylim[1])\n",
    "\n",
    "# set x, y label. \n",
    "plt.xlabel(r\"$\\rm age_{\\rm true}$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm age_{\\rm pred}-\\rm age_{\\rm true}$ \", fontsize=18)\n",
    "\n",
    "# draw y=0 line\n",
    "xline = np.linspace(xlim[0],xlim[1], 2)\n",
    "yline = np.zeros_like(xline)\n",
    "plt.plot(xline,yline,linestyle='--',c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13,9))\n",
    "plt.scatter(np.power(10, age_true-9.0), np.power(10, age_pred-9.0), s= 70)\n",
    "#plt.scatter( age_true,  age_pred, s= 70)\n",
    "plt.xlabel(r\"$\\rm age_{\\rm true}\\rm(Gyr)$\", fontsize=18)\n",
    "plt.ylabel(r\"$\\rm age_{\\rm pred}\\rm(Gyr)$\", fontsize=18)\n",
    "plt.title('cross-validation', fontsize = 20)\n",
    "#plt.axis([0.0, 20.0, 0.0, 25.0])\n",
    "plt.tick_params(labelsize=18)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot true log(g) vs. trueTeff (i.e. HR diagram) and \n",
    "#colour coded with the |age_pred-age_true|. \n",
    "\n",
    "\n",
    "plt.figure(figsize=(13,9))\n",
    "marker_size = 70\n",
    "#plt.scatter(teff_true, logg_true, s= marker_size, c= np.power(10,age_diff-9.0), cmap ='jet' )\n",
    "plt.scatter(teff_true, logg_true, s= marker_size, c= np.power(10,age_diff-9.0), cmap ='jet' )\n",
    "plt.tick_params(labelsize=18)\n",
    "plt.xlabel('log(Teff)', fontsize=18)\n",
    "plt.ylabel('log(g)', fontsize=18)\n",
    "plt.title('cross-validation', fontsize = 20)\n",
    "plt.axis([4.5, 3.3, 6, -0.5])\n",
    "cbar= plt.colorbar()\n",
    "cbar.set_label(r\"($\\rm age_{\\rm pred}-\\rm age_{\\rm true})$\" , labelpad=+1, fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
